{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework with Yelp reviews data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This assignment uses a small subset of the data from Kaggle's [Yelp Business Rating Prediction](https://www.kaggle.com/c/yelp-recsys-2013) competition.\n",
    "\n",
    "**Description of the data:**\n",
    "\n",
    "- **`yelp.csv`** contains the dataset. It is stored in the course repository (in the **`data`** directory), so there is no need to download anything from the Kaggle website.\n",
    "- Each observation (row) in this dataset is a review of a particular business by a particular user.\n",
    "- The **stars** column is the number of stars (1 through 5) assigned by the reviewer to the business. (Higher stars is better.) In other words, it is the rating of the business by the person who wrote the review.\n",
    "- The **text** column is the text of the review.\n",
    "\n",
    "**Goal:** Predict the star rating of a review using **only** the review text.\n",
    "\n",
    "**Tip:** After each task, I recommend that you check the shape and the contents of your objects, to confirm that they match your expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "Read **`yelp.csv`** into a Pandas DataFrame and examine it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  stars  \\\n",
       "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "2  6oRAC4uyJCsJl1X0WZpVSA  2012-06-14  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
       "3  _1QQZuf4zZOyFCvXc0o6Vg  2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4  6ozycU1RpktNG2-1BroVtw  2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "1  I have no idea why some people give bad review...  review   \n",
       "2  love the gyro plate. Rice is so good and I als...  review   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4  General Manager Scott Petello is a good egg!!!...  review   \n",
       "\n",
       "                  user_id  cool  useful  funny  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0  \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ     0       0      0  \n",
       "2  0hT2KtfLiobPvh6cDC8JQg     0       1      0  \n",
       "3  uZetl9T0NcROGOyFfughhg     1       2      0  \n",
       "4  vYmM4KTsC8ZfQBg-j5MWkw     0       0      0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read form the csv file and print first rows\n",
    "yelp_dataset = pd.read_csv(\"../data/yelp.csv\")\n",
    "yelp_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# The dataset consist in 10000 datapoints with 10 features per datapoint\n",
    "print(yelp_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Create a new DataFrame that only contains the **5-star** and **1-star** reviews.\n",
    "\n",
    "- **Hint:** [How do I apply multiple filter criteria to a pandas DataFrame?](https://www.youtube.com/watch?v=YPItfQ87qjM&list=PL5-da3qGB5ICCsgW1MxlZ0Hq8LL5U3u9y&index=9) explains how to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>zp713qNhx8d9KCJJnrw1xA</td>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>riFQ3vxNpP4rWLk_CSri2A</td>\n",
       "      <td>5</td>\n",
       "      <td>Drop what you're doing and drive here. After I...</td>\n",
       "      <td>review</td>\n",
       "      <td>wFweIWhv2fREZV_dYkz_1g</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  stars  \\\n",
       "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "3  _1QQZuf4zZOyFCvXc0o6Vg  2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4  6ozycU1RpktNG2-1BroVtw  2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "6  zp713qNhx8d9KCJJnrw1xA  2010-02-12  riFQ3vxNpP4rWLk_CSri2A      5   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "1  I have no idea why some people give bad review...  review   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4  General Manager Scott Petello is a good egg!!!...  review   \n",
       "6  Drop what you're doing and drive here. After I...  review   \n",
       "\n",
       "                  user_id  cool  useful  funny  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0  \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ     0       0      0  \n",
       "3  uZetl9T0NcROGOyFfughhg     1       2      0  \n",
       "4  vYmM4KTsC8ZfQBg-j5MWkw     0       0      0  \n",
       "6  wFweIWhv2fREZV_dYkz_1g     7       7      4  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can filter in a DataFrame using the notation foo[(foo.var1 > x) & or | (foo.var2 == y)]\n",
    "yelp_binary = yelp_dataset[(yelp_dataset.stars == 1) | (yelp_dataset.stars == 5)]\n",
    "yelp_binary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4086, 10)\n"
     ]
    }
   ],
   "source": [
    "# Only 4086 datapoints have 1 star or 5 stars.\n",
    "print(yelp_binary.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "Define X and y from the new DataFrame, and then split X and y into training and testing sets, using the **review text** as the only feature and the **star rating** as the response.\n",
    "\n",
    "- **Hint:** Keep in mind that X should be a Pandas Series (not a DataFrame), since we will pass it to CountVectorizer in the task that follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4086,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice that I use capital x, means that is a matrix, in this case a matrix of 4086x1\n",
    "X = yelp_binary.text\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    My wife took me here on my birthday for breakf...\n",
       "1    I have no idea why some people give bad review...\n",
       "3    Rosie, Dakota, and I LOVE Chaparral Dog Park!!...\n",
       "4    General Manager Scott Petello is a good egg!!!...\n",
       "6    Drop what you're doing and drive here. After I...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4086,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = yelp_binary.stars\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5\n",
       "1    5\n",
       "3    5\n",
       "4    5\n",
       "6    5\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3064,)\n",
      "(3064,)\n",
      "(1022,)\n",
      "(1022,)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "# Let's confirm the data shapes\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "\n",
    "Use CountVectorizer to create **document-term matrices** from X_train and X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Instanciate it\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we 'learn' the vocabulary from the training data\n",
    "vect.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16825\n"
     ]
    }
   ],
   "source": [
    "# Let's examine the features we learnt\n",
    "feature_names = vect.get_feature_names()\n",
    "print(len(feature_names))\n",
    "# print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the data document-term matrix\n",
    "X_train_dtm = vect.transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "# TODO: examine the shapes of the matrix and visualise the dtm matrix using pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "\n",
    "Use Multinomial Naive Bayes to **predict the star rating** for the reviews in the testing set, and then **calculate the accuracy** and **print the confusion matrix**.\n",
    "\n",
    "- **Hint:** [Evaluating a classification model](https://github.com/justmarkham/scikit-learn-videos/blob/master/09_classification_metrics.ipynb) explains how to interpret both classification accuracy and the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import and instantiate a Multinomial Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1022,)\n",
      "(1022,)\n"
     ]
    }
   ],
   "source": [
    "nb.fit(X_train_dtm, y_train)\n",
    "y_pred_class = nb.predict(X_test_dtm)\n",
    "# Confirm that both shapes are the same\n",
    "print(y_pred_class.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91878669275929548"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see how we did !!\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[126,  58],\n",
       "       [ 25, 813]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see the confusion Matrix\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92563600782778865"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see the accuracy using logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_dtm, y_train)\n",
    "y_pred = logreg.predict(X_test_dtm)\n",
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[140,  44],\n",
       "       [ 32, 806]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It has a slightly higher accuracy, let's see the confusion matrix\n",
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using logistic regression we have a much better understanding of the reviews class1- True negatives\n",
    "# We have decreased the false positives(44), but increased the false negatives(32) and true positives(806)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's investigate what makes a review to fall in 1 or 5 stars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16825"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tokens = vect.get_feature_names()\n",
    "len(X_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 16825)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.feature_count_\n",
    "nb.feature_count_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Array with each token count for each class\n",
    "one_star_token_count = nb.feature_count_[0,:]\n",
    "five_star_token_count = nb.feature_count_[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokens = pd.DataFrame({'token':X_train_tokens, 'onestar':one_star_token_count, 'fivestar':five_star_token_count}).set_index('token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fivestar</th>\n",
       "      <th>onestar</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>blue</th>\n",
       "      <td>54.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>curtains</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sooooo</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mel</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thrilled</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>viagra</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grits</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nowhere</th>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>immune</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passing</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fivestar  onestar\n",
       "token                      \n",
       "blue          54.0     11.0\n",
       "curtains       1.0      1.0\n",
       "sooooo         5.0      0.0\n",
       "mel            2.0      0.0\n",
       "thrilled       9.0      0.0\n",
       "viagra         0.0      1.0\n",
       "grits         15.0      1.0\n",
       "nowhere        8.0      3.0\n",
       "immune         4.0      0.0\n",
       "passing        5.0      2.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine 10 DataFrame rows\n",
    "tokens.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6 (Challenge)\n",
    "\n",
    "Calculate the **null accuracy**, which is the classification accuracy that could be achieved by always predicting the most frequent class.\n",
    "\n",
    "- **Hint:** [Evaluating a classification model](https://github.com/justmarkham/scikit-learn-videos/blob/master/09_classification_metrics.ipynb) explains null accuracy and demonstrates two ways to calculate it, though only one of those ways will work in this case. Alternatively, you can come up with your own method to calculate null accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    838\n",
       "1    184\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Null Accuracy is the accuracy of the classifier if we always predict the most likely class.\n",
    "# Find out which class is the most likely (assuming that the data is distributed in the same\n",
    "# way in training and test datasets)\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    0.819961\n",
      "Name: stars, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def get_null_accuracy(targets):\n",
    "    \"\"\"\n",
    "    Returns the accuracy if we always\n",
    "    predict the most repeated class\n",
    "    \n",
    "    TODO: Extend this method to general cases\n",
    "    \"\"\"\n",
    "    return targets.value_counts().head(1) / len(targets)\n",
    "\n",
    "null_accuracy = get_null_accuracy(y_test)\n",
    "print(null_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7 (Challenge)\n",
    "\n",
    "Browse through the review text of some of the **false positives** and **false negatives**. Based on your knowledge of how Naive Bayes works, do you have any ideas about why the model is incorrectly classifying these reviews?\n",
    "\n",
    "- **Hint:** [Evaluating a classification model](https://github.com/justmarkham/scikit-learn-videos/blob/master/09_classification_metrics.ipynb) explains the definitions of \"false positives\" and \"false negatives\".\n",
    "- **Hint:** Think about what a false positive means in this context, and what a false negative means in this context. What has scikit-learn defined as the \"positive class\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This has to be the worst restaurant in terms of hygiene. Two of my friends had food -poisoning after having dinner here. The food is just unhealthy with tons of oil floating on the top of curries, and I am not sure if any health/hygiene code is followed here. \\nThe service is poor and the information on its website is incorrect, the owner does not allow dine-in after 9 or 10 even though it says that the restaurant is open till 11. \\n\\nOne night I saw the owner cleaning the place without gloves and she was nice enough to give us a to-go parcel without cleaning her hands (great example to the servers!). I had a peek inside the kitchen when the door was ajar, and it definitely looked dirty.\\n\\nI have been a lot of hole-in-the-wall places around this restaurant, including Haji Baba, the Vietnamese place and others, but neither any of my friends nor I have fallen sick coz of the food. If you need a spicy-food fix, i strongly recommend you do not try this place, lest you want a visit to the doctor the very next day.',\n",
       " \"If you like the stuck up Scottsdale vibe this is a good place for you. The food isn't impressive. Nice outdoor seating.\",\n",
       " \"I'm sorry to be what seems to be the lone one star review.  Either I got there on the worst day in their history, or everyone drank the Koolaid, or I just have different expectations and taste buds.\\nIt seems like a great idea.  It's a build your own burger joint, $7.00 gets you a cooked to order burger with one cheese, up to 4 toppings, and 2 sauces with fries or onion rings-or some other choices.  They also claim that the beef is local, hormone free, etcetera....\\n\\nI chose a rare burger with American, grilled onions, sauteed mushrooms. tomato and lettuce, with mayo and mustard on a potato bun.  I added bacon for a dollar.\\n\\nFirst, let me point out that if you are in a hurry, DON'T GO HERE TO EAT.  I waited exactly 39 minutes for my food. This would not be a big deal if:\\n1.  I had been warned before they ran my credit card--what if I only had 30 minutes for lunch??\\n2. They had places to sit but it's tiny and full.\\n3.  They had magazines, a jukebox, ANYTHING to entertain you for 39 minutes.  You can't even get your drink early to sip on that.\\n\\nAt the 30 minute mark, I'm ready to eat cardboard with a little ketchup on it, so maybe they make you wait so everything tastes even better?\\nAnyway, before my burger comes up, I notice that the lady behind the counter is saying that the orders overwhelmed the kitchen.  I look in the kitchen---they have ONE GUY TRYING TO DO ALL THIS??????   He'd better be getting a share of the profits!!!!!  Now I'm jsut feeling really bad for this guy back there.\\n\\nI finally get my burger!  YAY!!  I'm SO excited!  All those 4 and 5 star reviews!  I take a bite and....the patty shoots out the other side of the bun like it had been shot out of a cannon.\\nWTH?  I look at the patty.  It's clean as a whistle. I mean there is no mayo or mustard or cheese smeared on the patty.  I turn it over and it slides out of my fingers back into the basket.  The other side is clean too.  The freakin' burger was so greasy, it slid all over the place!  Then a greasy glop of what must have  been the mushrooms and onions slid out.  Still not seeing any cheese, mayo, or mustard anywhere.  Just oil.  Tons and tons of oil.  I open the bun,  On one side is a heavily oiled slick of lettuce glued to the bun by (I am guessing) a slice of cheese.  The other side of the bun has some mayo and mustard residue--and more oil.  I'm grossed out, but hungry.  I take a bite.  It's not rare,  It's well done and oddly, tastes very faintly of liver.  BTW, remember the bacon I paid a dollar for?  Not there.  I'm really puzzled that instead of cheese. or beef, or SOMETHING, I just taste that faint livery taste. So I take another bite.There isn't even any salt or pepper, or anything on the burger patty.  This is perhaps, the worst grade of meat available for human consumption.  I take a third bite because that second bite brought back a memory of when I worked for a meat company here in town.  Now I recognize the flavor.  I'm not saying that what I ate that day at Two Hippies was old dairy cow, but that's EXACTLY what it tasted like.\\n\\nAt this point, I turn to the fries.  The are shriveled and DARK and taste like they've been fried and then microwaved.\\n\\nI couldn't get out of there fast enough!  Forget my danged dollar!  just get me in the car!\\n\\nExactly one hour and 20 minutes later, I had vicious diarrhea\\n\\nI haven't had that trouble even with eating junk food at the fair!\\n\\nNo.  NO.  A thousand times NO!\\n\\nRed Robin is my next burger stop.  Period\",\n",
       " \"Went last night to Whore Foods to get basics to make pizza with, most clutch to the process was a three pack of yeast. Low and behold, the dirty hippie kids they have working there again didn't put something in the bag.\\n\\nAnd this time it was the yeast.\\n\\nI love the food there, but the employees are nothing more than entitled hippie kids from Scottsdale who can't be bothered to do their goddamn jobs! I am so sick of this crap with this corporation. Maybe its a Phoenix thing, or maybe its the hiring and firing processes of Whore Foods, but I am done shopping at any Whore Foods. In a place like Phoenix, where you have alternatives such as Sprouts, you'd think Whore Foods would smarten up.\\n\\nOr when you try to ask someone who works here where something is, and they just walk by with their nose high in the air. I understand its important to show your fellow dirt merchants that you're a super star, but I don't work with you, I contribute to your salary and over inflated set of benefits for a grocery clerk, so do your goddamn job. Useless little girl in need of a shower and orthodontist. \\n\\nBut alas, Whore Foods and its dirty hippie employees have alienated yet another person with a job and a degree into hating everything that place stands for.\\n\\nOh yea, one other thing, take the concealed firearm prohibition off of your stores. It didn't stop Jared Loughner from doing something horrid, and all it does is alienate law abiding citizens from their Constitutional rights. I understand you think that only parts of the Constitution should apply, but honestly I think you need to pull your collective heads out of your ass and take a shower.\\n\\nUseless motherf*&#$@s!\",\n",
       " \"I found Lisa G's while driving through phoenix with a friend. The exterior looked promising and we prepared ourselves for a treat. We were in for a a shock! We ordered the antipasto plate and while there were serious issues with it, it turned out to be the best thing we were served. I ordered the chicken rolatini (the special of the day) and it was just plain bad! The chicken was dry and under seasoned, the Rosemary potatoes were soggy  and the veggie medley  (squash, corn, green beans, etc.) was over cooked and the juices spilled over into the potatoes. It was one of the worst $17 meals that I have ever had! My friend ordered the veggie salad and it was one literal hot mess. Just horrible food! I see that others had the mini burgers and bowl of balls and found them to be tasty. I wish I had ordered those. As it is this is one place I would never revisit or recommend to a friend!\",\n",
       " 'Don\\'t know where I should start. Grand opening was on September 17th, 2010. We went to try this new Dim Sum place at the Mekong Plaza as they heavily advertised in the chinese newspapers and were advertising 30% off.\\n\\nWhen I got there, the biggest eyesore is that they tried to make their portion of the Food Court as a regular \"Chinese\" restaurant. So imagine the picture of chandeliers hanging in the middle of a food court in the mall. It just looks too tacky, I thought they should\\'ve went with a more fast food type Dim sum like they have in San Gabriel, California.\\n\\nUpon checking in with the hostess, they don\\'t even issue numbers, they only call you by name. So that was already pretty different from how usual chinese restaurant run things. Totally not efficient at all.\\n\\nOnce we finally got a seat, things got worse.\\n\\nOur \"Har Gow\"/Shrimp dumpling was raw! The skin was thick and clumpy, the shrimp was severely undercooked. We asked them to exchange for another one, and it was still raw. We also had to exchange the shrimp egg roll as it was also raw. Their excuse was that they were too busy and did not have time to fully cook the food. Ok.....so how are the other 100s of asian restaurants able to serve dim sum at a fast pace with fully cooked food? That was probably the lamest excuse.\\n\\nThe trademark \"beef internal organs\" that I always love to order was pathetic. They charged the large price for a tiny little bowl, there were only a few tendons and mostly filled with Daikon. \\n\\nThe BBQ Pork bun, another staple of Dim sum, was not that great either. There was barely any char siu in the bun, and the exterior of the bun was not fully cooked.\\n\\nI understand that it is their first operating weekend, but the idea of a nice chinese dimsum place at a food court just doesn\\'t fly in my opinion. They even offer wedding banquets here too. \\n\\nI don\\'t think I\\'ll be returning here unless they really upgrade the quality of the food. The idea is definitely novel, but will be a hard sell.',\n",
       " \"Went last week, and ordered a dozen variety. I didn't care for any of them, very dry, the frosting wasn't very good,even my 9 yr old daughter spit her cupcake out!\",\n",
       " 'Never Again,\\nI brought my Mountain Bike in (which I bought 1 week earlier from Walmart) to have them replace my flat inner tubes with puncture resistant tubes.)  I came back 20 minutes later when they said it would be done and as I rode away, the back tire rhythmically rubbed against the back brake.  When I returned and told them about it, I was told the back wheel was not true.  It was true for the whole short week since I purchased it from Walmart.  I plan to take it to their competitor (Landis) and pay the extra $15-$25) to have the wheel put back to the straight condition it was in when I brought it to Slippery Pig in the first place.   I would never give a shop another penny for an extra service I should never have needed on a brand new bike which coasted perfectly when I brought it in.',\n",
       " \"My wife and I live around the corner, hadn't eaten here in a few months. We got food for take out, Mongolian beef,kung po chicken,pad Thai noodles.  Mongolian beef, there were more white onions then scallions and it was very bland. Kung po chicken,lots of white meat chicken the whole dish only had one peanut and the taste of this dish was non existent. Very very Blah... Pad Thai noodles,the dish was dry and came out of the container in one giant clump. It tasted like plain noodles, i was glad I had peanut sauce in the fridge to,add to it. Then it was edible .... We will not be going back to G@S.. Very disappointed !!!! From now on it will be Jade palace on 92nd street. For take out Asian !!!!  Do yourself a favor go elsewhere !!!!\",\n",
       " 'D-scust-ing.']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's print some false positives. False positive -> we predict 5 when the actual value is 1.\n",
    "# The predictions from the Bayes Algorithm are stored in y_pred_class\n",
    "false_positives = X_test[y_pred_class > y_test]\n",
    "list(false_positives)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I now consider myself an Arizonian. If you drive a lot on the 101 or 51 like I do, you'll get your fair share of chips on your windshield. You'll also have to replace a windshield like I had to do just recently. Apparently, chips and cracking windshields  is common in Arizona. In fact, I seem to recall my insurance agent telling me that insurance companies must provide this coverage in Arizona.\\n\\nI had a chip repaired about a year ago near the very bottom of the windshield. Just recently a small, very fine crack started traveling north on the windshield from the repaired chip (a different vendor repaired the chip). I called these guys over to my house and they said it was too long to fix, so they replaced the whole windshield the next day.\\n\\nWhat great service, they come out to your residence or place of business to repair or replace your windshield.\",\n",
       " 'This is by far my favourite department store, hands down. I have had nothing but perfect experiences in this store, without exception, no matter what department I\\'m in. The shoe SA\\'s will bend over backwards to help you find a specific shoe, and the staff will even go so far as to send out hand-written thank you cards to your home address after you make a purchase - big or small. Tim & Anthony in the shoe salon are fabulous beyond words! \\n\\nI am not completely sure that I understand why people complain about the amount of merchandise on the floor or the lack of crowds in this store. Frankly, I would rather not be bombarded with merchandise and other people. One of the things I love the most about Barney\\'s is not only the prompt attention of SA\\'s, but the fact that they aren\\'t rushing around trying to help 35 people at once. The SA\\'s at Barney\\'s are incredibly friendly and will stop to have an actual conversation, regardless or whether you are purchasing something or not. I have also never experienced a \"high pressure\" sale situation here.\\n\\nAll in all, Barneys is pricey, and there is no getting around it. But, um, so is Neiman\\'s and that place is a crock. Anywhere that ONLY accepts American Express or their charge card and then treats you like scum if you aren\\'t carrying neither is no place that I want to spend my hard earned dollars. Yay Barneys!',\n",
       " 'Since I have ranted recently on poor customer service, and in the spirit of balance, here is a shining example of how easy it really is.\\n\\nLate last summer  I came home and was shocked to see two of my sunscreens looking quite vandalized. Upon further inspection, it appeared that while using a back mounted leaf blower, one of the landscape crew had brushed against them. The exhaust pipe must have ripped and burned the screen material as well. It was quite the nasty burned melted scar.\\n\\n After staring at it for several hours, I realized there was no virgin Mary, no Jesus, hell it just looked like burned grilled cheese without any deity or lesser apparitions whatsoever, regardless of the angle or my squint. So deciding there was no money to made on eBay, I set out to get them repaired.\\n\\nDid some online searching and decided to call AmeriZona. I explained the situation and was told they could repair them, but I would have to bring them in. These are some pretty large sun screens mind you and packing them into the convertible would have been a challenge.\\n\\nWhile pondering what to do the person helping me on the phone asked me if I could hold on. I could tell it was one of those thinking on your feet light bulb went off type can you hold requests.\\n\\nShe came back on the phone, informed me that she had a crew that was working close by and that she would ask one of the crew to swing by and pick up the screens for repair. She could not promise when they would be repaired, but for that convenience alone I was on board. She had already quoted me the price to repair the screens, and it was very reasonable considering some other online comparisons.\\n\\nSomeone showed up within a few hours to pick up the screens. He could not have been more accommodating, and it was obvious this guy had been working all day and was on his way home. \\n\\nA few days later, Mark  phoned me to tell me my screens were ready and to tell me he was going to drop them off on his way home! Needless to say Mark was also very pleasant to deal with. I believe he was at the time the sales manager. \\n\\nWhen he arrived, the screens looked great, matched the color of the others, even with the sun bleaching over several years. He even offered to put them in! \\n\\nThis experience was way beyond any customer service expectations. No extra charges for any of the above and beyond the call of duty efforts. Outstanding, and quite refreshing.',\n",
       " 'This is a must try for any Mani Pedi fan. I use to drive to Scottsdale for all of my services until I found this spot. Get the pedi, no metal file pedi once - and you will NEVER go any where else. Have fun. I do..Customer service - top end. Thanks',\n",
       " 'I`ve had work done by this shop a few times thruoghout the past few years. My latest experience was when my sons car broke its timing belt and needed substantial repairs. Bob informed us that he could move the car out of the way in his lot to be safely stored until we decided whether we wanted to fix it or not. This is just one of the reasons why I`ll always bring my business to him.',\n",
       " 'I was there last week with my sisters and while we ordered our steaks cooked medium, all of them came out well done. Kind of disappointed, but oh well.\\n\\nSo last night my fiance and I had a buy-one-get-one-free coupon, so we headed over. When I ordered my steak cooked medium, I asked her to make a point of it when she put the order in because of the issue last week.\\n\\nWhen our food came out, she asked me to cut into my steak and make sure it was cooked the way I wanted. I did and, while it was a bit more medium-well than medium, I was hungry and it looked good, so I gave it the go ahead and we started our meal. It really was a good steak.\\n\\nWhen our waitress came out again, she double checked that my steak was cooked correctly. I assured her it was fine. A few minutes later a manager came out and apologized for my steak being over done and offered to replace it. I assured him it was maybe a little overdone, but it was good and I was happy with my meal. They were being very nice and showing some great customer service, though a little overzealous. :)\\n\\nWhen the bill came, they had made my steak the free one for the coupon, even though mine was the more expensive of the two meals we ordered.\\n\\nGreat customer service, and very good food.',\n",
       " \"I went to sears today to check on a layaway that I placed online but was going to pickup here. Margaret, the associate couldn't find me in her system so she personally called the sears.com help line to find out what was happening. She was friendly, professional, and extremely helpful in solving my problem. I went home a happy customer and am very thankful to Margaret for her help!\",\n",
       " \"I've passed by prestige nails in walmart 100s of times but never really thought of having a pedicure there (even though they are always busy!) As I stared at my feet, long overdue for a pedicure, I thought it was about time to try them...since walmart rarely let's me down why should the nail salon inside?\\n\\nTo my surprise I got a wonderful pedicure or $23 not too bad this day in age...my to mention it was just as good as going to the more upscale salon just across the street! \\n\\nI'm glad to be the first to review them they deserve it! Now if only they did facials at walmart and hair I'd be set!\",\n",
       " 'This place is so great! I am a nanny and had to bring in a dance outfit to get the straps shorten for the girl I care for. The woman did this for no charge! It was only the second time I went there. She said it would only take her two minutes so no charge. She was super sweet!',\n",
       " \"I was sad to come back to lai lai's and they no longer had the Mongolian :( boo,, but i took my mom there and we were starving so we decided to order off the menu. My mom is allergic to  msg and they helped us with what we should order. and she didn't get sick!! woo hoo.. we ordered three dishes and an appetizer to share between her , my bf, and myself, and we stilll brought food home, and I dont think we spent over $30 bucks for all that food!! it was very good to! i love good cheap food!! Ill be back, they are always friendly.\"]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# False Negatives are class1 predictions when the actual class is 5\n",
    "false_negatives = X_test[y_pred_class < y_test]\n",
    "list(false_negatives)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8 (Challenge)\n",
    "\n",
    "Calculate which 10 tokens are the most predictive of **5-star reviews**, and which 10 tokens are the most predictive of **1-star reviews**.\n",
    "\n",
    "- **Hint:** Naive Bayes automatically counts the number of times each token appears in each class, as well as the number of observations in each class. You can access these counts via the `feature_count_` and `class_count_` attributes of the Naive Bayes model object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 26.,   4.,   1.,   3.,   1.])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numpy arrays for the number of times that each token is in one/five star reviews\n",
    "one_star_tokens = nb.feature_count_[0,:]\n",
    "five_star_tokens = nb.feature_count_[1,:]\n",
    "# First 5 tokens example\n",
    "one_star_tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We'll add 1 to avoid dividing by 0 when calculating the ratio\n",
    "one_star_tokens = one_star_tokens + 1\n",
    "five_star_tokens = five_star_tokens + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>five_star</th>\n",
       "      <th>one_star</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>teenager</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vittles</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quiona</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cine</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opinion</th>\n",
       "      <td>31.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delish</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insists</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patronize</th>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usps</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           five_star  one_star\n",
       "token                         \n",
       "teenager         3.0       2.0\n",
       "vittles          2.0       1.0\n",
       "quiona           2.0       1.0\n",
       "cine             2.0       1.0\n",
       "opinion         31.0       7.0\n",
       "delish          37.0       1.0\n",
       "rec              2.0       1.0\n",
       "insists          2.0       1.0\n",
       "patronize        7.0       4.0\n",
       "usps             2.0       1.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = pd.DataFrame({'token': X_train_tokens, 'one_star': one_star_tokens, 'five_star': five_star_tokens}).set_index('token')\n",
    "tokens.sample(10, random_state=7)\n",
    "# The token opinion appears 31 times in a 5* review and only 7 in a 1* review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>five_star</th>\n",
       "      <th>one_star</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>teenager</th>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.003540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vittles</th>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.001770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quiona</th>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.001770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cine</th>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.001770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opinion</th>\n",
       "      <td>0.012405</td>\n",
       "      <td>0.012389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          five_star  one_star\n",
       "token                        \n",
       "teenager   0.001200  0.003540\n",
       "vittles    0.000800  0.001770\n",
       "quiona     0.000800  0.001770\n",
       "cine       0.000800  0.001770\n",
       "opinion    0.012405  0.012389"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's some tokens ratios\n",
    "tokens['one_star'] = tokens.one_star / nb.class_count_[0]\n",
    "tokens['five_star'] = tokens.five_star / nb.class_count_[1]\n",
    "tokens.sample(5, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we can compare the 1* vs 5* ratios and add it to the panda series\n",
    "tokens['one_to_five_ratio'] = tokens.one_star / tokens.five_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>five_star</th>\n",
       "      <th>one_star</th>\n",
       "      <th>one_to_five_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>teenager</th>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.003540</td>\n",
       "      <td>2.948673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vittles</th>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>2.211504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quiona</th>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>2.211504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cine</th>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>2.211504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opinion</th>\n",
       "      <td>0.012405</td>\n",
       "      <td>0.012389</td>\n",
       "      <td>0.998744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delish</th>\n",
       "      <td>0.014806</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.119541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec</th>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>2.211504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insists</th>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>2.211504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patronize</th>\n",
       "      <td>0.002801</td>\n",
       "      <td>0.007080</td>\n",
       "      <td>2.527434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usps</th>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>2.211504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           five_star  one_star  one_to_five_ratio\n",
       "token                                            \n",
       "teenager    0.001200  0.003540           2.948673\n",
       "vittles     0.000800  0.001770           2.211504\n",
       "quiona      0.000800  0.001770           2.211504\n",
       "cine        0.000800  0.001770           2.211504\n",
       "opinion     0.012405  0.012389           0.998744\n",
       "delish      0.014806  0.001770           0.119541\n",
       "rec         0.000800  0.001770           2.211504\n",
       "insists     0.000800  0.001770           2.211504\n",
       "patronize   0.002801  0.007080           2.527434\n",
       "usps        0.000800  0.001770           2.211504"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.sample(10, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>five_star</th>\n",
       "      <th>one_star</th>\n",
       "      <th>one_to_five_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>staffperson</th>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.030088</td>\n",
       "      <td>75.191150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refused</th>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.024779</td>\n",
       "      <td>61.922124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgusting</th>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.042478</td>\n",
       "      <td>53.076106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filthy</th>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.019469</td>\n",
       "      <td>48.653097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unacceptable</th>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.015929</td>\n",
       "      <td>39.807080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acknowledge</th>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.015929</td>\n",
       "      <td>39.807080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unprofessional</th>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.015929</td>\n",
       "      <td>39.807080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ugh</th>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.030088</td>\n",
       "      <td>37.595575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yuck</th>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.028319</td>\n",
       "      <td>35.384071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuse</th>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.014159</td>\n",
       "      <td>35.384071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disaster</th>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.014159</td>\n",
       "      <td>35.384071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boca</th>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.014159</td>\n",
       "      <td>35.384071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>voucher</th>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.014159</td>\n",
       "      <td>35.384071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hire</th>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.014159</td>\n",
       "      <td>35.384071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rude</th>\n",
       "      <td>0.002801</td>\n",
       "      <td>0.093805</td>\n",
       "      <td>33.488496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pischke</th>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.012389</td>\n",
       "      <td>30.961062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nibbles</th>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.012389</td>\n",
       "      <td>30.961062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>innova</th>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.012389</td>\n",
       "      <td>30.961062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pointing</th>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.012389</td>\n",
       "      <td>30.961062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inedible</th>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.012389</td>\n",
       "      <td>30.961062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rudely</th>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.012389</td>\n",
       "      <td>30.961062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flag</th>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.012389</td>\n",
       "      <td>30.961062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horrible</th>\n",
       "      <td>0.004002</td>\n",
       "      <td>0.116814</td>\n",
       "      <td>29.191858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sucked</th>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.023009</td>\n",
       "      <td>28.749558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst</th>\n",
       "      <td>0.003601</td>\n",
       "      <td>0.099115</td>\n",
       "      <td>27.520944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gross</th>\n",
       "      <td>0.002401</td>\n",
       "      <td>0.065487</td>\n",
       "      <td>27.275221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spilled</th>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.010619</td>\n",
       "      <td>26.538053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actions</th>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.010619</td>\n",
       "      <td>26.538053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>busses</th>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.010619</td>\n",
       "      <td>26.538053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blowdry</th>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.010619</td>\n",
       "      <td>26.538053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peanut</th>\n",
       "      <td>0.011204</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.157965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tart</th>\n",
       "      <td>0.011204</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.157965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>farm</th>\n",
       "      <td>0.011204</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.157965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awesome</th>\n",
       "      <td>0.114446</td>\n",
       "      <td>0.017699</td>\n",
       "      <td>0.154651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dentist</th>\n",
       "      <td>0.011605</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.152518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>affordable</th>\n",
       "      <td>0.012005</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.147434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dr</th>\n",
       "      <td>0.037215</td>\n",
       "      <td>0.005310</td>\n",
       "      <td>0.142678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creative</th>\n",
       "      <td>0.012405</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.142678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>die</th>\n",
       "      <td>0.025610</td>\n",
       "      <td>0.003540</td>\n",
       "      <td>0.138219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creamy</th>\n",
       "      <td>0.012805</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.138219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vibe</th>\n",
       "      <td>0.012805</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.138219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offers</th>\n",
       "      <td>0.013605</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.130088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hubby</th>\n",
       "      <td>0.013605</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.130088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flavors</th>\n",
       "      <td>0.044018</td>\n",
       "      <td>0.005310</td>\n",
       "      <td>0.120628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delish</th>\n",
       "      <td>0.014806</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.119541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gelato</th>\n",
       "      <td>0.014806</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.119541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>authentic</th>\n",
       "      <td>0.029612</td>\n",
       "      <td>0.003540</td>\n",
       "      <td>0.119541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variety</th>\n",
       "      <td>0.030012</td>\n",
       "      <td>0.003540</td>\n",
       "      <td>0.117947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>organic</th>\n",
       "      <td>0.015206</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.116395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classes</th>\n",
       "      <td>0.015206</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.116395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amazing</th>\n",
       "      <td>0.185274</td>\n",
       "      <td>0.021239</td>\n",
       "      <td>0.114635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mozzarella</th>\n",
       "      <td>0.015606</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.113410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pasty</th>\n",
       "      <td>0.015606</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.113410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gem</th>\n",
       "      <td>0.016006</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.110575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brunch</th>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.105310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outstanding</th>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.090265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>favorite</th>\n",
       "      <td>0.138055</td>\n",
       "      <td>0.012389</td>\n",
       "      <td>0.089742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yum</th>\n",
       "      <td>0.024810</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.071339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perfect</th>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.005310</td>\n",
       "      <td>0.054159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fantastic</th>\n",
       "      <td>0.077231</td>\n",
       "      <td>0.003540</td>\n",
       "      <td>0.045834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16825 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                five_star  one_star  one_to_five_ratio\n",
       "token                                                 \n",
       "staffperson      0.000400  0.030088          75.191150\n",
       "refused          0.000400  0.024779          61.922124\n",
       "disgusting       0.000800  0.042478          53.076106\n",
       "filthy           0.000400  0.019469          48.653097\n",
       "unacceptable     0.000400  0.015929          39.807080\n",
       "acknowledge      0.000400  0.015929          39.807080\n",
       "unprofessional   0.000400  0.015929          39.807080\n",
       "ugh              0.000800  0.030088          37.595575\n",
       "yuck             0.000800  0.028319          35.384071\n",
       "fuse             0.000400  0.014159          35.384071\n",
       "disaster         0.000400  0.014159          35.384071\n",
       "boca             0.000400  0.014159          35.384071\n",
       "voucher          0.000400  0.014159          35.384071\n",
       "hire             0.000400  0.014159          35.384071\n",
       "rude             0.002801  0.093805          33.488496\n",
       "pischke          0.000400  0.012389          30.961062\n",
       "nibbles          0.000400  0.012389          30.961062\n",
       "innova           0.000400  0.012389          30.961062\n",
       "pointing         0.000400  0.012389          30.961062\n",
       "inedible         0.000400  0.012389          30.961062\n",
       "rudely           0.000400  0.012389          30.961062\n",
       "flag             0.000400  0.012389          30.961062\n",
       "horrible         0.004002  0.116814          29.191858\n",
       "sucked           0.000800  0.023009          28.749558\n",
       "worst            0.003601  0.099115          27.520944\n",
       "gross            0.002401  0.065487          27.275221\n",
       "spilled          0.000400  0.010619          26.538053\n",
       "actions          0.000400  0.010619          26.538053\n",
       "busses           0.000400  0.010619          26.538053\n",
       "blowdry          0.000400  0.010619          26.538053\n",
       "...                   ...       ...                ...\n",
       "peanut           0.011204  0.001770           0.157965\n",
       "tart             0.011204  0.001770           0.157965\n",
       "farm             0.011204  0.001770           0.157965\n",
       "awesome          0.114446  0.017699           0.154651\n",
       "dentist          0.011605  0.001770           0.152518\n",
       "affordable       0.012005  0.001770           0.147434\n",
       "dr               0.037215  0.005310           0.142678\n",
       "creative         0.012405  0.001770           0.142678\n",
       "die              0.025610  0.003540           0.138219\n",
       "creamy           0.012805  0.001770           0.138219\n",
       "vibe             0.012805  0.001770           0.138219\n",
       "offers           0.013605  0.001770           0.130088\n",
       "hubby            0.013605  0.001770           0.130088\n",
       "flavors          0.044018  0.005310           0.120628\n",
       "delish           0.014806  0.001770           0.119541\n",
       "gelato           0.014806  0.001770           0.119541\n",
       "authentic        0.029612  0.003540           0.119541\n",
       "variety          0.030012  0.003540           0.117947\n",
       "organic          0.015206  0.001770           0.116395\n",
       "classes          0.015206  0.001770           0.116395\n",
       "amazing          0.185274  0.021239           0.114635\n",
       "mozzarella       0.015606  0.001770           0.113410\n",
       "pasty            0.015606  0.001770           0.113410\n",
       "gem              0.016006  0.001770           0.110575\n",
       "brunch           0.016807  0.001770           0.105310\n",
       "outstanding      0.019608  0.001770           0.090265\n",
       "favorite         0.138055  0.012389           0.089742\n",
       "yum              0.024810  0.001770           0.071339\n",
       "perfect          0.098039  0.005310           0.054159\n",
       "fantastic        0.077231  0.003540           0.045834\n",
       "\n",
       "[16825 rows x 3 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.sort_values('one_to_five_ratio', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9 (Challenge)\n",
    "\n",
    "Up to this point, we have framed this as a **binary classification problem** by only considering the 5-star and 1-star reviews. Now, let's repeat the model building process using all reviews, which makes this a **5-class classification problem**.\n",
    "\n",
    "Here are the steps:\n",
    "\n",
    "- Define X and y using the original DataFrame. (y should contain 5 different classes.)\n",
    "- Split X and y into training and testing sets.\n",
    "- Create document-term matrices using CountVectorizer.\n",
    "- Calculate the testing accuracy of a Multinomial Naive Bayes model.\n",
    "- Compare the testing accuracy with the null accuracy, and comment on the results.\n",
    "- Print the confusion matrix, and comment on the results. (This [Stack Overflow answer](http://stackoverflow.com/a/30748053/1636598) explains how to read a multi-class confusion matrix.)\n",
    "- Print the [classification report](http://scikit-learn.org/stable/modules/model_evaluation.html#classification-report), and comment on the results. If you are unfamiliar with the terminology it uses, research the terms, and then try to figure out how to calculate these metrics manually from the confusion matrix!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
